% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bayes.RBM.R
\name{detect.bayes.RBM}
\alias{detect.bayes.RBM}
\title{Bayesian Stopping Rule for RBM Data}
\usage{
detect.bayes.RBM(test, n.iter = 100, n.hidden = 30,
  learning.rate = 0.1, size.minibatch = 10, momentum = 0.5,
  lambda = 0.001, alpha, nulower = NULL, nuupper = NULL,
  score = "hyvarinen", c = 0.5, n = 1000, lenth1, lenth0,
  thlower1 = NULL, thupper1 = NULL, thlower0 = NULL,
  thupper0 = NULL, GENTH1 = NULL, ULPTH1 = NULL, GENTH0 = NULL,
  ULPTH0 = NULL, ULP0 = NULL, GLP0 = NULL, LLP0 = NULL,
  ULP1 = NULL, GLP1 = NULL, LLP1 = NULL, par0 = NULL,
  par1 = NULL, lenx = NULL, lower0 = NULL, upper0 = NULL,
  lower1 = NULL, upper1 = NULL)
}
\arguments{
\item{test}{A matrix with binary features of shape samples * features,
the data that need to detect.}

\item{n.iter}{Defines the number of epochs to run contrastive diversion.}

\item{n.hidden}{The number of nodes in the hidden layer.}

\item{learning.rate}{The learning rate, alpha, for training the system.}

\item{size.minibatch}{The size of the minibatches used for training.}

\item{momentum}{Speeds up the gradient descent learning.}

\item{lambda}{The sparsity penalty lambda to prevent the system from overfitting.}

\item{alpha}{A numeric parameter in \code{(0,1)} that controls the probability
of false alarm.}

\item{nulower, nuupper}{Optional nonnegative numerics: The earliest and latest
time of changepoint based on prior belief. The default is \code{nulower=0}
and \code{nuupper=18} which corresponds to the geometric prior distribution
with \code{p=0.1}.}

\item{score}{An optional character specifying the type of score to be used:
The default \code{"hyvarinen"} or the conventional \code{"logarithmic"}.
Can be abbreviated. Case insensitive.}

\item{c, n}{Optional parameters of the Sequentital Monte Carlo algorithm: ESS
threshold \code{0<c<1} and sample size \code{n>0}. Default is \code{c=0.5}
and \code{n=1000}. The resample-move step is triggered whenever the ESS
goes below \code{c*n}.}

\item{lenth1}{A positive numeric: The length of the variable of the unknown
parameter in the post-change model.}

\item{lenth0}{A positive numeric: The length of the variable of the unknown
parameter in the pre-change model.}

\item{thlower1, thupper1}{Optional numeric vectors of length \code{lenth}: The
lower and upper limits of the unknown parameter in the post-change model.
The defaults are infinite.}

\item{thlower0, thupper0}{Optional numeric vectors of length \code{lenth}: The
lower and upper limits of the unknown parameter in the pre-change model.
The defaults are infinite.}

\item{GENTH1}{An optional function that takes a sample size and returns a
random sample from the prior distribution of the unknown parameter in the
post-change model. Default is standard normal on the unconstrained
space. Required if \code{ULPTH1} is specified.}

\item{ULPTH1}{An optional function: The log unnormalized probability function
of the prior distribution of the unknown parameter in the post-change
model. Default is standard normal on the unconstrained space. Required
if \code{GENTH1} is specified.}

\item{GENTH0}{An optional function that takes a sample size and returns a
random sample from the prior distribution of the unknown parameter in the
pre-change model. Default is standard normal on the unconstrained
space. Required if \code{ULPTH0} is specified.}

\item{ULPTH0}{An optional function: The log unnormalized probability function
of the prior distribution of the unknown parameter in the pre-change
model. Default is standard normal on the unconstrained space. Required
if \code{GENTH0} is specified.}

\item{ULP0, GLP0, LLP0}{Functions of an observation and a numeric parameter:
The log unnormalizedprobability function, its gradient and its laplacian
for the pre-change model. If \code{score="hyvarinen"}, either
\{\code{GLP0,LLP0}\} or \code{ULP0} is required. The former is recommended. In
the latter case,\{\code{GLP0,LLP0}\} will be computed via
\code{\link[pracma]{grad}} and \code{\link[pracma]{laplacian}}.
If \code{score="logarithmic"}, only \code{ULP0} is required.}

\item{ULP1, GLP1, LLP1}{Functions of an observation and a numeric parameter:
The log unnormalized probability function, its gradient and its laplacian
for the post-change model. If \code{score="hyvarinen"}, either
\{\code{GLP1,LLP1}\} or \code{ULP1} is required. The former is recommended. In
the latter case, \{\code{GLP1,LLP1}\} will be computed via
\code{\link[pracma]{grad}} and \code{\link[pracma]{laplacian}}. If
\code{score="logarithmic"}, only \code{ULP1} is required.}

\item{par0, par1}{Optional numeric parameters for the pre-change
(\code{par0}) and post-change (\code{par1}) models, except if
\code{score="logarithmic"} that \code{par1} is a function of the unknown
parameter in the post-change model. If \code{score="hyvarinen"}, the positive
tuning parameter with a default of 1. If \code{score="logarithmic"}, the
negative log normalizing constant. If omitted, will be computed via
\code{\link[stats]{integrate}} (if \code{lenx=1}) or
\code{\link[cubature]{hcubature}} (if \code{lenx>1}).}

\item{lenx}{A positive numeric: The length of the variable of an obervation.
Optional if \code{score="hyvarinen"} or if \code{score="logarithmic"} and
\code{par0,par1} are specified.}

\item{lower0, upper0, lower1, upper1}{Optional numeric vectors of length
\code{lenx}: The lower and upper limits of an observation from the
pre-change (\code{lower0,upper0}) and post-change (\code{lower1,upper1})
models. The defaults are infinite.}
}
\value{
A named numeric vector with components
\enumerate{
  \item{\code{t}} {A positive numeric: The stopping time.}
  \item{\code{LER}} {A numeric in \code{(0,1)}: The low ESS rate, i.e., the proportion of iterations that ESS drops below \code{c*n}.}
  \item{\code{AAR}} {A numeric in \code{(0,1)}: The average acceptance rate of the Metropolis-Hastings sampling in the move step. \code{NaN} if ESS never drops below \code{c*n}.}
}
}
\description{
Changepoint detection for data following RBM model using the Bayesian stopping rule.
}
\examples{
# Load the MNIST data
data(MNIST)
# true change happens at 47
test <- MNIST$testX[c(which(MNIST$testY==0),which(MNIST$testY==1)),][151:250,]

# suppose cauchy priors
ULP1=function(x,th) -log(1+((x-th[1])/th[2])^2)
ULP0=function(x,th) -log(1+((x-th[1])/th[2])^2)
par1=function(th) pi*th[2]
par0=function(th) pi*th[2]

# log score
detect.bayes.RBM(test,alpha=0.5 ,nulower=20, nuupper=100,lenth1=2, lenth0=2, thlower1=c(-Inf,0),thlower0=c(-Inf,0),score="logarithmic",ULP0=ULP0,ULP1=ULP1,lenx=1)

# hyvarinen score
detect.bayes.RBM(test,alpha=0.5 ,nulower=20,nuupper=100,lenth1=2, lenth0=2, thlower1=c(-Inf,0),thlower0=c(-Inf,0),score="hyvarinen",ULP0=ULP0,ULP1=ULP1,par1=0.01, par0=0.01)

}
